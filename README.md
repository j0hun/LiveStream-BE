# 🎥 스트리밍 서버 프로젝트

다양한 스트리밍 방식(WebRTC P2P, WebRTC SFU, AMS 서버를 이용한 WebRTC → RTP → HLS, Nginx-RTMP)의 성능을 비교 분석하여 서비스 규모에 따른 최적의 스트리밍 방식을 파악하기 위해 진행하였습니다.


프론트엔드 깃허브 주소: https://github.com/j0hun/LiveStream-FE

---
## 🔧 테스트 환경

### 방송자 환경

- **CPU**: Intel i5-8265U (1.6GHz, 4코어 8스레드)
- **메모리**: 24GB RAM

### 서버 환경

- **플랫폼**: Google Cloud Platform VM 인스턴스
- **CPU**: Intel Xeon @ 2.20GHz (1코어 2스레드)
- **메모리**: 4GB RAM

### 인프라 구성

- **컨테이너 환경**: Docker Compose
- **리버스 프록시**: Nginx + Certbot (HTTPS)
- **모니터링**: Grafana, Prometheus

---

## 🛠️ 기술 스택

- **Frontend**: React, WebRTC
- **Backend**: Spring Boot, REST API
- **서버 배포**: Docker, Docker Compose
- **리버스 프록시**: Nginx, Certbot
- **클라우드 환경**: Google Cloud Platform
- **모니터링 툴**: Grafana, Prometheus

---

## 📊 테스트 방식

- 방송자가 스트리밍 송출을 시작한 후 시청자를 최대 50명까지 증가시키며 CPU 사용률 측정
- 브라우저 자동화 도구인 Puppeteer를 활용해 VM 인스턴스 5개를 만들어서 시청자 50명 테스트

---

## 📌 성능 테스트 결과

| 스트리밍 방식                      | 방송자 CPU (송출) | 방송자 CPU (시청자 50명) | 서버 CPU (송출) | 서버 CPU (시청자 50명) | 분석                       |
| ---------------------------- | ------------ | ----------------- | ----------- | ---------------- | ------------------------ |
| **WebRTC P2P** (7명)          | 22%          | 80% (한계 도달)       | 8%          | 8%               | 소규모 방송 적합, 방송자 CPU 급증    |
| **WebRTC SFU (Janus)** (50명) | 18%          | 18%               | 11%         | 54%              | 서버 부하가 중간 수준으로 중규모 방송 적합 |
| **WebRTC -> RTP -> HLS (AMS)** (50명)         | 21%          | 21%               | 35%         | 45%              | 중규모 적합 |
| **Nginx-RTMP** (50명)         | 26%          | 26%               | 11%         | 15%              | 대규모 방송 적합, 서버 부하 최소      |

---

## 🚨 트러블슈팅 과정

### 1️⃣ HTTPS에서만 WebRTC 작동
- **문제 상황**: 로컬 환경에서 잘되던 WebRTC가 배포 환경에서 스트림이 나오지 않음
- **원인 분석**: WebRTC는 HTTPS 환경에서만 작동함을 확인
- **해결 방법**: 리버스 프록시(Nginx + Certbot)를 이용하여 HTTPS 환경으로 배포

### 2️⃣ 시청자 수 증가 시 CPU 과부하 (WebRTC P2P)
- **문제 상황**: WebRTC P2P 방식에서 시청자 7명 이상 시 방송자 CPU 사용률 급격히 증가
- **원인 분석**: P2P 방식은 방송자가 모든 시청자에게 개별 스트림을 전송하므로 부하 급증
- **해결 방법**: WebRTC SFU 방식으로 변경하여 방송자 CPU 부하 감소

### 3️⃣ VM 인스턴스 간 Puppeteer 테스트 중 브라우저 인스턴스 제한
- **문제 상황**: 하나의 VM에서 Puppeteer로 10명 이상의 시청자를 동시에 테스트 시 자원 한계 초과
- **원인 분석**: 단일 VM 인스턴스의 CPU 및 메모리 자원 부족으로 브라우저 인스턴스 제한 발생
- **해결 방법**: VM 인스턴스를 5개로 분산하여 각 인스턴스 당 10명의 시청자 실행으로 자원 분산

---

## ✨ 프로젝트를 통해 배운 점

- 스트리밍 방식별 특성과 서비스 규모에 따른 자원 활용 효율성을 실험을 통해 명확히 분석
- 도커 및 클라우드 환경(GCP)을 활용한 실제 서비스 배포와 운영 방법 습득
- 서비스 요구사항에 따라 기술 스택 및 아키텍처를 결정하는 과정 이해

